---
title: "R Notebook"
output: html_notebook
---


```{r}
library(dplyr)
library(stringr)

# loading in all the urls that are gathered through Octoparse and cleaning them
#set1
data <- read.csv('allurls(1).csv')

data <- data %>%
  mutate_at('Field2_links', str_replace, 'https://', '')
datafinal <- data %>%
  select(4)

# save to csv again 
write.csv(datafinal, 'rawurls1.csv', row.names = F, col.names = F)

#set2
data2 <- read.csv('allurls(2).csv')

data2 <- data2 %>%
  mutate_at('Field2_links', str_replace, 'https://', '')
datafinal2 <- data2 %>%
  select(4)

# save to csv again 
write.csv(datafinal2, 'rawurls2.csv', row.names = F, col.names = F)

#set3
data3 <- read.csv('allurls(3).csv')

data3 <- data3 %>%
  mutate_at('Field2_links', str_replace, 'https://', '')
datafinal3 <- data3 %>%
  select(4)

# save to csv again 
write.csv(datafinal3, 'rawurls3.csv', row.names = F, col.names = F)

#set4
data4 <- read.csv('allurls(4).csv')

data4 <- data4 %>%
  mutate_at('Field2_links', str_replace, 'https://', '')
datafinal4 <- data4 %>%
  select(4)

# save to csv again 
write.csv(datafinal4, 'rawurls4.csv', row.names = F, col.names = F)

#set5
data5 <- read.csv('allurls(5).csv')

data5 <- data5 %>%
  mutate_at('Field2_links', str_replace, 'https://', '')
datafinal5 <- data5 %>%
  select(4)

# save to csv again 
write.csv(datafinal5, 'rawurls5.csv', row.names = F, col.names = F)

```


```{r}
# merging the 5 datasets into 1 set and after that dividing them into little sets to import to the scrapers
final_set <- rbind(datafinal, datafinal2, datafinal3, datafinal4, datafinal5)
final_set_urls <- distinct(final_set)

write.csv(d[['1']], 'urls1.csv', row.names = F, col.names = F)
write.csv(d[['2']], 'urls2.csv', row.names = F, col.names = F)
write.csv(d[['3']], 'urls3.csv', row.names = F, col.names = F)
write.csv(d[['4']], 'urls4.csv', row.names = F, col.names = F)
write.csv(d[['5']], 'urls5.csv', row.names = F, col.names = F)
write.csv(d[['6']], 'urls6.csv', row.names = F, col.names = F)
write.csv(d[['7']], 'urls7.csv', row.names = F, col.names = F)
write.csv(d[['8']], 'urls8.csv', row.names = F, col.names = F)
write.csv(d[['9']], 'urls9.csv', row.names = F, col.names = F)
write.csv(d[['10']], 'urls10.csv', row.names = F, col.names = F)
write.csv(d[['11']], 'urls11.csv', row.names = F, col.names = F)
write.csv(d[['12']], 'urls12.csv', row.names = F, col.names = F)
write.csv(d[['13']], 'urls13.csv', row.names = F, col.names = F)
write.csv(d[['14']], 'urls14.csv', row.names = F, col.names = F)
write.csv(d[['15']], 'urls15.csv', row.names = F, col.names = F)
write.csv(d[['16']], 'urls16.csv', row.names = F, col.names = F)
write.csv(d[['17']], 'urls17.csv', row.names = F, col.names = F)


```
